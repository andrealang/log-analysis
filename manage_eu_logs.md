---

copyright:
  years:  2018, 2019
lastupdated: "2019-07-18"

keywords: LogDNA, IBM, Log Analysis, logging, overview

subcollection: LogDNA

---

{:new_window: target="_blank"}
{:shortdesc: .shortdesc}
{:screen: .screen}
{:pre: .pre}
{:table: .aria-labeledby="caption"}
{:codeblock: .codeblock}
{:tip: .tip}
{:download: .download}
{:important: .important}
{:note: .note}

# Managing logs for EU-managed resources
{: #manage_eu_logs}

EU-managed reasources: apps, services, compute resources such as CF, clusters, VSI
{:shortdesc}

Across every industry, organizations require tighter controls and visibility into where their data is stored and processed in the {{site.data.keyword.cloud_notm}}. 

To **manage logs that are generated by EU-managed {{site.data.keyword.cloud_notm}} services and Cloud Foundry (CF) resources** by using the {{site.data.keyword.la_full}} service, you must provision 1 logging instance in the `EU-DE (Frankfurt)` location. Then, you must enable this logging instance to collect service platform logs.
* To manage logs from {{site.data.keyword.cloud_notm}} services, you must provision services in the Frankfut location.
* To manage logs from Cloud Foundry (CF), you must provision CF applications in the Frankfurt location. 

To manage logs from Kubernetes clusters
To manage logs from VMwares
To manage logs from apps and services that are running outside the IBM Cloud

comply with EU regulations.

 that collect logs from those apps and services. You must restrict access to users to see and manage these logs. You must ensure that you archive to an EU-Supported {{site.data.keyword.cos_full_notm}} (COS) bucket. In addition, you must enable your account to be `EU-Supported` so support is handled by team members in the European Union. 


## Step 1. Set on the EU-Supported flag in your account
{: #manage_eu_logs_step1}

You must enable your account to be `EU-Supported`. 

Consider the following information when you turn on the `EU Supported` flag in your account:
* Support is handled by team members in the European Union. 
* In the event your issue requires non-EU expert assistance, it will be reviewed and approval given prior to any non-EU intervention.
* You can filter and identify the Catalog services that are EU-managed so users can only provision EU-Supported {{site.data.keyword.cloud_notm}} services.

When you enable your account to `EU-Supported`, you agree to 
If you select the EU Support option, the most common support issues will be limited to an IBM Cloud team located in the European Union. In the event your issue requires non-EU expert assistance, it will be reviewed and approval given prior to any non-EU intervention. Additionally, in order to support and update the services, cross-border Processing of your data may still occur. Please ensure you take the necessary actions to allow this Processing, as detailed in the Cloud Service Terms. A standard Data Processing Addendum is available here.

Orders using the API will proceed without additional notifications. The terms related to selecting products, services, or locations outside the EU apply to API orders. Users you create and API keys you generate will have the ability to order products, services, and locations outside of the EU. It is your responsibility to educate anyone you grant access to your account on the consequences and requirements if they make a selection that is not in the EU Supported option.

## Step 2. Provision {{site.data.keyword.la_full_notm}} instances in Frankfurt 
{: #manage_eu_logs_step2}

You can provision {{site.data.keyword.la_full_notm}} instances in multiple [locations](/docs/services/Log-Analysis-with-LogDNA?topic=LogDNA-regions). However, only instances that are provisioned in the `EU-DE (Frankfurt` location are EU-Supported.
{: important}

For more information on how to provision an instance, see [Provisioning an instance](/docs/services/Log-Analysis-with-LogDNA?topic=LogDNA-provision).


## Step 3. Configure 1 instance to manage service platform logs
{: #manage_eu_logs_step3}

You can provision 1 or more instances in the Franfurt location. However, only 1 of those instances can be configured to collect platform service logs for resources that run in the Frankfurt location. For more information on how to configure an instance to collect platform service logs, see [Configuring service logs](/docs/services/Log-Analysis-with-LogDNA?topic=LogDNA-config_svc_logs).

Check out the list of {{site.data.keyword.cloud_notm}} resources that automatically collect logs and forward them to your logging instance. See [platform service logs](/docs/services/Log-Analysis-with-LogDNA?topic=LogDNA-cloud_services).



## Step 4.Configure your LogDNA agents
{: #manage_eu_logs_step4}

When you configure a LogDNA agent, you specify to which instance that agent connects. You can only connect 1 agent to a LogDNA instance. 

If you have agents that collect logs from resources, apps and services that run in the {{site.data.keyword.cloud_notm}} or outside the {{site.data.keyword.cloud_notm}}, and that must be EU-managed, you need to configure your agents to forward data to a logging instance in Frankfurt.

Learn more about how to [detach an agent](/docs/services/Log-Analysis-with-LogDNA?topic=LogDNA-detach_agent) from a logging instance and how to [configure an agent](/docs/services/Log-Analysis-with-LogDNA?topic=LogDNA-config_agent) to forward logs to a specific instance.



## Step 5. Restrict user access to view and manage logs
{: #manage_eu_logs_step5}

{{site.data.keyword.iamlong}} (IAM) enables you to securely authenticate users and control access to all cloud resources consistently in the {{site.data.keyword.cloud_notm}}.

**Every user that accesses the {{site.data.keyword.la_full_notm}} service in your account must be assigned an access policy with an IAM user role defined.** The policy determines what actions the user can perform within the context of the service or instance you select. The allowable actions are customized and defined as operations that are allowed to be performed on the service. The actions are then mapped to IAM user roles.

You might have users across different geographies. However, to comply with EU law, only EU personel can see and access log data from your EU-managed infrastructure, apps, and services. To restrict access to users, you can configure an access group, and define policies that restrict access to those users to the instances in Frankfurt.

### Grant permissions to users to manage the logging service
{: #manage_eu_logs_step5-1}

To grant administrator permissions to users, complete the following steps:
1. Create an access group, then add users to it. For example, create an access group named `logdna-eu-admins`. [Learn more](/docs/iam?topic=iam-groups#create_ag).
2. [Assign access to a group](/docs/iam?topic=iam-groups#access_ag) by configuring policies.

    For example, you can add a policy to the access group for each instance of the {{site.data.keyword.la_full_notm}} service in Frankfurt. For each policy, select the platform role **administrator** if you want administrators of the logging service to be able to grant other users permissions to work with logging instances in Frankfurt. If you want to remove permissions to manage users to administrators of the logging service in your account, choose the platform role **editor**. Select the service role **manager**.


### Grant permissions to users to view logs
{: #manage_eu_logs_step5-2}

To grant viewer permissions to users, complete the following steps:
1. Create an access group, then add users to it. For example, create an access group named `logdna-eu-users`. [Learn more](/docs/iam?topic=iam-groups#create_ag).
2. [Assign access to a group](/docs/iam?topic=iam-groups#access_ag) by configuring policies.

    For example, you can add a policy to the access group for each instance of the {{site.data.keyword.la_full_notm}} service in Frankfurt. For each policy, select the platform role **viewer** to grant users permissions to view logs. Select the service role **reader**.


## Step 4. Exporting logs
{: #manage_eu_logs_step4}

To make the EU-DE (Frankfurt) location `EU-Supported`, the web UI export functionality is not available for instances that are provisioned in Frankfurt. In addition, you cannot use the API to export data to an email address. 

You can export data to a local file or to a terminal by using the LogDNA export API and a service key. Only administrators can create service keys. Users can view them. Service keys are only used to export data from your instance by using the API.

Notice that users in the account that have permissions to view logs through the LogDNA web UI can export data by using the API if they have an active service key. A user, with a policy in IAM to view logs, can also view service keys that an administrator has created. If you do not want users to be able to export data locally, service keys must be deleted. 


## Step 5. Archiving logs
{: #manage_eu_logs_step5}

When you archive logs from a LogDNA instance to a COS bucket, consider the following information:
* You must provision an instance of the COS service in Frankfurt.
* You must configure a bucket that complies with the EU-Supported and GDPR regulations. 

    * For a bucket with **single site** resiliency, create the bucket in Amsterdam or Milan.

    * For a bucket with **regional** resiliency, create the bucket in the `EU-DE` location to keep the data in Frankfurt.

    * For a bucket with **cross region** resiliency, create the bucket in the `eu-geo` location. Data is kept within the EU geography across datacenters that are located in Milan, Amsterdam, and Frankfurt.

* You must restrict user access to manage archived log files in these buckets.  
* Users are responsible for downloading files to EU-managed locations.

To learn how to configure archiving for your LogDNA instance, see [Archiving logs](/docs/services/Log-Analysis-with-LogDNA?topic=LogDNA-archiving).



## Step 6. Querying archived logs with SQL Query service
{: #manage_eu_logs_step6}


{{site.data.keyword.sqlquery_short}} provides a serverless, no-ETL solution to easily query data stored in COS.

Once you have SQL Query running on IBM Cloud, you can immediately start querying your data using the SQL Query user interface, programmatically by using either the REST API or the Python `ibmcloudsql` library, or write a serverless function by using {{site.data.keyword.openwhisk_short}}.
You can use the {{site.data.keyword.sqlquery_short}} service to analyze data from archive files in COS. 

When you query logs, consider the following information:
* You must provision an instance of the {{site.data.keyword.sqlquery_short}} service in Frankfurt.
* You must restrict user access to 

When you click Open UI, the SQL Query service will automatically generate a unique Cloud Object Storage bucket that will store all of the results as CSV files from your SQL queries. You can also specify other buckets to store results in




